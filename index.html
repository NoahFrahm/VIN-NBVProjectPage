<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="we propose the View Introspection Network (VIN), which is trained
  to predict the reconstruction quality improvement of views directly, and the VIN-
  NBV policy. A greedy sequential sampling-based policy, where at each acquisi-
  tion step, we sample multiple query views and choose the one with the highest
  VIN predicted improvement score. We design the VIN to perform 3D-aware fea-
  turization of the reconstruction built from prior acquisitions, and for each query
  view create a feature that can be decoded into an improvement score. We then
  train the VIN using imitation learning to predict the reconstruction improvement
  score. We show that VIN-NBV improves reconstruction quality by∼30% over a
  coverage maximization baseline when operating with constraints on the number
  of acquisitions or the time in motion.">
  <meta property="og:title" content="VIN-NBV: A View Introspection Network for
  Next-Best-View Selection for Resource-Efficient 3D
  Reconstruction"/>
  <meta property="og:description" content="Next Best View (NBV) algorithms aim to acquire an optimal set of im-
  ages using minimal resources, time, or number of captures to enable efficient 3D
  reconstruction of a scene. Existing approaches often rely on prior scene knowl-
  edge or additional image captures and often develop policies that maximize cov-
  erage. Yet, for many real scenes with complex geometry and self-occlusions,
  coverage maximization does not lead to better reconstruction quality directly. In
  this paper, we propose the View Introspection Network (VIN), which is trained
  to predict the reconstruction quality improvement of views directly, and the VIN-
  NBV policy. A greedy sequential sampling-based policy, where at each acquisi-
  tion step, we sample multiple query views and choose the one with the highest
  VIN predicted improvement score. We design the VIN to perform 3D-aware fea-
  turization of the reconstruction built from prior acquisitions, and for each query
  view create a feature that can be decoded into an improvement score. We then
  train the VIN using imitation learning to predict the reconstruction improvement
  score. We show that VIN-NBV improves reconstruction quality by∼30% over a
  coverage maximization baseline when operating with constraints on the number
  of acquisitions or the time in motion."/>
  <meta property="og:url" content="https://noahfrahm.github.io/VIN-NBVProjectPage/"/>
  
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">

  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="3D Reconstruction, Next Best View, Coverage Maximization, Imitation Learning, Deep Learning, Robotics, Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>VIN-NBV</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/faviconm.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <style>
  
    /* html, body, h1, h2, h3, h4, h5, h6 {
			font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
			margin: 0;
			padding: 0;
		} */

		.cite {
			padding: 0px;
			background: #ffffff;
			font-size: 18px;
		}

		.card {
			border: 1px solid #ccc
		}

		p {
			font-size: 18px;
		}

		a {
			text-decoration: none;
			color: #2196F3;
		}
		
		.bibtexsection {
			width: 100%;
			height: 12em;
			font-family: "Courier", monospace;
			white-space: pre;
			background-color: #f4f4f4;
			margin-left: auto;
			margin-right: auto;
			text-align: left;
		}

		table {
			text-align: center;
			margin-left: auto;
			margin-right: auto;
			border-collapse: collapse;
		}

		#seq-container {
			margin-top: 40px;
			margin-bottom: 40px;
			display: flex;
			flex-direction: column;
			align-items: center;
		}

		button {
			padding: 10px;
			border: none;
			cursor: pointer;
			background: #dce8f7;
			color: #000;
			font-size: 14px;
			text-align: center;
			height: 40px;
			width: 130px;
		}

		button.pipeline-btn{
			width: 120px;
		}

		button.selected {
			background: #9bc8ff; /* Lighter background for selected */
			color: #000;
			font-weight: bold;
		}

		#seq-header {
			margin-bottom: 0px;
			text-align: center;
		}

		#container {
			width: 100%;
			margin: 0 auto;
			display: flex;
			gap: 16px;
			justify-content: space-between;
			align-items: flex-start;
			flex-wrap: nowrap;
		}


		.viewer-row{
		width:100%;
		margin:0 auto 20px;
		display:grid;
		grid-template-columns:repeat(4, 1fr);   /* four equal columns */
		gap:5px;                               /* uniform spacing */
		}

		.viewer-wrapper{
		display:flex;
		flex-direction:column;
		align-items:center;
		}

		.viewer{
		width:100%;
		aspect-ratio:1/1;        /* perfect square */
		position:relative;
		background:#eee;
		border:1px solid #333;
		overflow:hidden;
		}

		.viewer canvas{
		position:absolute;       /* stretch canvas to fill */
		top:0;left:0;width:100%;height:100%;
		}

		canvas {
			display: block;
			width: 100%;
			height: 100%;
		}

		select {
			font-size: 1rem;
			padding: 5px;
		}

		#video-container {
			width: 95%;             /*  MUST MATCH container  */
			margin: 10px auto;
			text-align: center;
		}

		#sequenceVideo {
			width: 100%;
			height: auto;
		}

		#custom-table {
			display: table;
			width: 100%; /* Adjust as needed */
			border-collapse: collapse;
			border-spacing: 0;
		}

		.table-row {
			display: table-row;
		}

		.small-image {
			width: 82%; /* Reduce the width slightly */
			height: auto; /* Maintain aspect ratio */
			object-fit: cover; /* Ensure the image fits nicely */
			margin: 0 auto; /* Center the image horizontally */
			display: block; /* Ensure proper layout */
		}

		.viewer-row-img{
      width:100%;
      margin:0 auto 20px;
      display:grid;
      grid-template-columns:repeat(3, 1fr);   /* six equal columns */
      gap:10px;                               /* uniform spacing */
		}


		.table-cell {
			display: table-cell;
			text-align: center; /* Center text horizontally */
			vertical-align: middle; /* Center text vertically */
			border: 1px solid white; /* White border lines */
			padding: 0px; /* Optional: adjust padding for spacing */
			background-color: transparent; /* No fill */
			color: black; /* Adjust text color if needed */
			width: 33.33%; /* Ensures all cells are of equal width */
		}

    .image-row {
      display: flex;
      justify-content: center; /* Centers the images horizontally */
      gap: 20px; /* Adds space between the images */
      flex-wrap: wrap; /* Allows images to wrap to the next line on smaller screens */
      margin: 20px 0; /* Adds vertical spacing */
    }

    .image-row img {
      max-width: 100%;
      height: auto;
      width: 45%; /* Adjusts the width of the images */
      border: 1px solid #ccc; /* Optional: Adds a border around images */
      border-radius: 4px; /* Optional: Rounds the corners of the images */
    }
	</style>
</head>
<body>

<!-- Paper Title and Authors -->
<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/noah-frahm-4118161b2" target="_blank">Noah Frahm</a>,</span>

                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/dongxu-zhao-109524154" target="_blank">Dongxu Zhao</a><sup>*</sup>,</span>

                  <span class="author-block">
                    <a href="https://github.com/asdunnbe" target="_blank">Andrea Dunn Beltran</a><sup>*</sup>,
                  </span>

                  <span class="author-block">
                    <a href="https://www.cs.unc.edu/~ron/" target="_blank">Ron Alterovitz</a>,
                  </span>

                  <span class="author-block">
                    <a href="" target="_blank">Jan-Michael Frahm</a>,
                  </span>

                  
                  <span class="author-block">
                    <a href="https://sites.google.com/cs.unc.edu/lupalab" target="_blank">Junier Oliva</a>,
                  </span>

                  <span class="author-block">
                    <a href="https://www.cs.unc.edu/~ronisen/" target="_blank">Roni Sengupta</a>
                  </span>

                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of North Carolina at Chapel Hill<br>(Under Review)</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.06219" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.06219" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Paper Title and Authors -->

<!-- Teaser Figure -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="MY ALT TEXT"/>
      <!-- <h2 class="subtitle has-text-centered">
        Average chamfer distance across all house objects as more acquisitions are made.
      </h2> -->
    </div>
  </div>
</section>
<!-- Teaser Figure -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-bottom: 2rem; margin-top: -0.5rem;">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Next Best View (NBV) algorithms aim to maximize 3D scene acquisition quality using minimal resources, e.g. number of acquisitions, time taken, or distance traversed. Prior methods often rely on coverage maximization as a proxy for reconstruction quality, but for complex scenes with occlusions and finer details, this is not always sufficient and leads to poor reconstructions. Our key insight is to train an acquisition policy that directly optimizes for reconstruction quality rather than just coverage. To achieve this, we introduce the View Introspection Network (VIN): a lightweight neural network that predicts the Relative Reconstruction Improvement (RRI) of a potential next viewpoint without making any new acquisitions. We use this network to power a simple, yet effective, sequential sampling-based greedy NBV policy. Our approach, VIN-NBV, generalizes to unseen object categories, operates without prior scene knowledge, is adaptable to resource constraints, and can handle occlusions. We show that our RRI fitness criterion leads to a ~30 gain in reconstruction quality over a coverage-based criterion using the same greedy strategy. Furthermore, VIN-NBV also outperforms deep reinforcement learning methods, Scan-RL and GenNBV, by ~40%.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Arch Diagram -->
<section class="section is-light">
  <div class="container is-max-desktop">
    <!-- <div class="columns is-centered has-text-centered">
      <h1 class="title is-3">Model architecture</h1>
    </div> -->
    <div class="columns is-centered has-text-centered">
      <h1 class="title is-3" style="margin-bottom: -2rem;">VIN-NBV Policy Overview</h1>
    </div>

    <div class="hero-body">
      <img src="static/images/combined_arch_diagram.png" alt="MY ALT TEXT"/>
      <p class="subtitle has-text-left" style="margin-top: 0.7rem;">
        Overview of the VIN-NBV Policy and the VIN architecture. The VIN is trained to predict the reconstruction improvement of a query view given a set of prior acquisitions. The VIN-NBV policy uses the VIN to select the next best view to acquire. The design of our policy makes it easy to modify with custom termination criteria and decision making logic.
      </p>
    </div>
  </div>
</section>
<!-- Arch Diagram -->

<!-- Chamfer distance graph + table -->
<section class="section is-light">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered" style="margin-top: -7rem;">
      <h1 class="title is-3" style="margin-bottom: -2.5rem;">Evaluation Results</h1>
    </div>

    <div class="hero-body">
      <img src="static/images/combined_chart_table.png" alt="MY ALT TEXT"/>
      <p class="subtitle has-text-left">
        We show the final average chamfer distance of our method compared to prior works evaluated on the OmniObject3D houses category for 20 captures. We also graph the average chamfer distance of our method as more acquisitions are made. We show that our method outperforms all prior works and that the chamfer distance improves as more acquisitions are made.
      </p>
    </div>
  </div>
</section>
<!-- Chamfer distance graph + table -->


<!-- Interactive Models -->
<section class="hero is-small-light">
  	<!-- Page Container -->
	<div class="w3-content w3-margin-top w3-margin-bottom" style="max-width:960px;">
  <!-- <div class="container is-max-desktop"> -->
        <div class="w3-display-container w3-row w3-white w3-margin-bottom">
				<div class="w3-center" style="margin-top: -5rem; margin-bottom: 2.2rem;">
					<h2 class="title is-3">10 Acquisition Comparison</h2>
				</div>

				<p class="subtitle has-text-left" style="margin-top:10px;">
					An interactive comparison of the final reconstruction after 10 total acquistions using our method (VIN-NBV) and our coverage baseline (Cov-NBV). Click the different object names to visualize more objects.
				</p>
	
        <div id="coverage-container">
					<div id="coverage-controls" style="display:flex;justify-content:center;margin:20px 0;gap:10px;">
						<button class="coverage-btn" data-set="m027">Motorcycle 27</button>
						<button class="coverage-btn" data-set="m013">Motorcycle 13</button>
						<button class="coverage-btn" data-set="h038">House 38</button>
						<button class="coverage-btn" data-set="h026">House 26</button>
						<button class="coverage-btn" data-set="h017">House 17</button>
					</div>
	
					<div id="coverage-row" class="viewer-row" style="grid-template-columns:repeat(2,1fr); gap: 10px; width: 75%;">
      					<div class="viewer-wrapper">
							<div class="viewer"><canvas id="canvasC0"></canvas></div>
							<h3>Cov-NBV</h3>
						</div>
      					<div class="viewer-wrapper">
							<div class="viewer"><canvas id="canvasC1"></canvas></div>
							<h3>VIN-NBV</h3>
						</div>
    				</div>
	
					<p style="font-size:14px; margin-top:10px;">
					<b>Controls:</b> Drag on any panel to rotate the shared camera; use the mouse wheel to zoom. Click
					<span id="reset-view-2" style="color: blue; text-decoration: underline; cursor: pointer;">here</span> to reset view to default.
					</p>
				</div>

				<hr>


				<div class="w3-center">
					<h2 class="title is-3" style="margin-top: 2.2rem; margin-bottom: 2.2rem;">Time in Motion Comparison</h2>
				</div>

				<p class="subtitle has-text-left" style="margin-top:10px;">
					We provide an interactive comparison of the final reconstruction under different time in motion limits. Under the different time limits the robot is forced to complete all acquistions in a certain time. The robot can move for a maximum of 15, 30, 45, and 60 seconds during acquistion. We compare our method (VIN-NBV) with the coverage baseline Cov-NBV and show the final results.
				</p>

		
        <div id="control-container" style="display:flex;flex-direction:row;justify-content:center;margin:20px 0;gap:20px;">
					<div id="pipeline-box" style="display: flex; flex-direction: row; align-items: center; gap: 10px;">
						<div style="display: flex; flex-direction: row; gap: 5px;">
							<button class="group1-btn" data-house="h004">House 4</button>
							<button class="group1-btn" data-house="h011">House 11</button>
							<button class="group1-btn" data-house="a005">Animal 5</button>
						</div>
					</div>
				</div>

				<div class="viewer-row-img" style="width: 70%;">
					<div class="viewer-wrapper">
						<div class="viewer">
							<img id="pic1"  class="small-image" style="margin-top: 3%;"/>
							<h5 class="w3-center">Base View 1</h5>
						</div>
					</div>

					<div class="viewer-wrapper">
						<div class="viewer">
							<img id="pic2"  class="small-image" style="margin-top: 3%;" />
							<h5 class="w3-center">Base View 2</h5>
						</div>
					</div>

					<div class="viewer-wrapper">
						<div class="viewer">
							<canvas id="canvasPC0"></canvas>
						</div>	
						<h5 class="w3-center">Initial Reconstruction (0s)</h5>					
					</div>
				</div>

				<h3 class="w3-center">Cov-NBV</h3>

				<div id="container-base" class="viewer-row">
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasB1"></canvas></div><h5>15 s</h5></div>
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasB2"></canvas></div><h5>30 s</h5></div>
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasB3"></canvas></div><h5>45 s</h5></div>
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasB4"></canvas></div><h5>60 s</h5></div>
				</div>
					
				<h3 class="w3-center">VIN-NBV</h3>

				<div id="container-ours" class="viewer-row">
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasO1"></canvas></div><h5>15 s</h5></div>
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasO2"></canvas></div><h5>30 s</h5></div>
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasO3"></canvas></div><h5>45 s</h5></div>
					<div class="viewer-wrapper"><div class="viewer"><canvas id="canvasO4"></canvas></div><h5>60 s</h5></div>
				</div>

				<p style="font-size:14px; margin-top:10px;">
					<b>Controls:</b> Drag on any panel to rotate the shared camera; use the mouse wheel to zoom. Click
					<span id="reset-view-1" style="color: blue; text-decoration: underline; cursor: pointer;">here</span> to reset view to default.

				</p>

				<hr>
		</div>
	</div>

<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" id="MathJax-script" async></script>
<link
	rel="stylesheet"
	href="https://unpkg.com/img-comparison-slider@7/dist/styles.css"
/>
<script type="module" src="main.js"></script>
</section>
<!-- Interactive Models -->



<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX" style="margin-top: -5rem;">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{frahm2025vinnbvviewintrospectionnetwork,
        title={VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction}, 
        author={Noah Frahm and Dongxu Zhao and Andrea Dunn Beltran and Ron Alterovitz and Jan-Michael Frahm and Junier Oliva and Roni Sengupta},
        year={2025},
        eprint={2505.06219},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2505.06219}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<!-- Acknowledgement for template -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. 
            Model Visualization code was adopted from the <a href="https://asdunnbe.github.io/NFL-BA/" target="_blank">NFL-BA</a> project page.
            
            <!-- You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative -->
            <!-- Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
<!-- Acknowledgement for template -->


<!-- Statcounter code for VIN-NBV Project Page
https://noahfrahm.github.io/VIN-NBVProjectPage/ on Google Sites (new) -->
<script type="text/javascript">
  var sc_project=13134560; 
  var sc_invisible=1; 
  var sc_security="09ff54e7"; 
 </script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img class="statcounter"
src="https://c.statcounter.com/13134560/0/09ff54e7/1/" alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

  </body>
  </html>
